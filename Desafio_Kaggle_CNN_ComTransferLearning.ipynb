{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1DLer2HUyaSpJxcAwr6YdmpDtFoSkX2Wv","timestamp":1686503632954}],"authorship_tag":"ABX9TyNvahTlEgmEsl32NkGqJPcC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**D3APL: Aplicações em Ciência de Dados** <br/>\n","IFSP Campinas\n","\n","Renata Rabelo e Mariana Cabride\n","\n","Prof. Dr. Samuel Martins (Samuka) <br/><br/>"],"metadata":{"id":"dF4ixE_CnLqa"}},{"cell_type":"markdown","source":["**Descrição:** Nesse notebook estamos usando a Convolutional Neural Network (CNN) customizada do primeiro notebook (Desafio_Kaggle_SemTransferLearning) que foi construída utilizando a interface Sequential do Keras. Porém, aqui estamos aplicando TransferLearning.\n"],"metadata":{"id":"_cfKP5GwPuH8"}},{"cell_type":"markdown","source":["### **Carregando as bibliotecas**"],"metadata":{"id":"HYQt4-8mnOBH"}},{"cell_type":"markdown","source":[" TensorFlow, os, pandas, numpy e random são importados. Essas bibliotecas são usadas para manipulação de dados, treinamento de redes neurais e outras operações relacionadas."],"metadata":{"id":"wQcd0Hac4N_f"}},{"cell_type":"code","source":["import tensorflow as tf\n","import pandas as pd\n","import numpy as np\n","import random\n","import os\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","from tensorflow.keras.optimizers import SGD\n","from tensorflow.keras.callbacks import EarlyStopping, TensorBoard"],"metadata":{"id":"-wEmMTMmnT8V","executionInfo":{"status":"ok","timestamp":1686507673904,"user_tz":180,"elapsed":7082,"user":{"displayName":"Renata Rabelo","userId":"10460000738836966178"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["### **Configuração dos seeds aleatórios**"],"metadata":{"id":"6kd-S4X3ndca"}},{"cell_type":"markdown","source":["Função reset_random_seeds(): Essa função configura as sementes aleatórias para garantir a reprodutibilidade dos resultados. Ela define as sementes para TensorFlow, NumPy e Python's Random."],"metadata":{"id":"eIPTVhs04XG9"}},{"cell_type":"code","source":["def reset_random_seeds(seed=42):\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    tf.random.set_seed(seed)\n","    np.random.seed(seed)\n","    random.seed(seed)\n","\n","reset_random_seeds()"],"metadata":{"id":"8TixJt_6ngxC","executionInfo":{"status":"ok","timestamp":1686503871401,"user_tz":180,"elapsed":4,"user":{"displayName":"Renata Rabelo","userId":"10460000738836966178"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["### **Montagem do Google Drive**"],"metadata":{"id":"73Fl0tbynqk6"}},{"cell_type":"markdown","source":["O código monta o Google Drive para acessar os arquivos de dados. Ele usa a biblioteca do Google Colab para essa finalidade."],"metadata":{"id":"QcPB8vqO4azz"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yj9WMKL8nsJ2","executionInfo":{"status":"ok","timestamp":1686503916605,"user_tz":180,"elapsed":45207,"user":{"displayName":"Renata Rabelo","userId":"10460000738836966178"}},"outputId":"ac668e00-742d-4690-9b36-1f4aee1e7702"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["### **Carregamento dos dados**"],"metadata":{"id":"nsxC-3GooQiM"}},{"cell_type":"markdown","source":["Os arquivos de treinamento e teste são carregados usando o pandas. Eles são armazenados em dataframes (dataset_df_train_completo e dataset_df_test, respectivamente). Após essa etapa, é feita a conversão dos rótulos das classes de formato de texto para números inteiros usando o LabelEncoder."],"metadata":{"id":"7cRXhUII4f3N"}},{"cell_type":"code","source":["data_dir = '/content/drive/MyDrive/Colab Notebooks/Kaggle/ifsp-d3apl-2023-face-recognition'\n","train_file = os.path.join(data_dir, 'train.csv')\n","test_file = os.path.join(data_dir, 'test.csv')\n","\n","dataset_df_train_completo = pd.read_csv(train_file)\n","dataset_df_test = pd.read_csv(test_file)\n","\n","# Conversão dos rótulos em formato de texto para números inteiros\n","label_encoder = LabelEncoder()\n","dataset_df_train_completo[\"label\"] = label_encoder.fit_transform(dataset_df_train_completo[\"label\"])"],"metadata":{"id":"KYjkzrtMnvN-","executionInfo":{"status":"ok","timestamp":1686503916606,"user_tz":180,"elapsed":23,"user":{"displayName":"Renata Rabelo","userId":"10460000738836966178"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["### **Divisão do conjunto de treinamento completo em treinamento e validação**"],"metadata":{"id":"twjjtztWoadK"}},{"cell_type":"markdown","source":["O conjunto de treinamento completo (dataset_df_train_completo) é dividido em conjuntos de treinamento e validação usando a função train_test_split do scikit-learn. Os dados são divididos em uma proporção de 80% para treinamento e 20% para validação. A variável labels contém as classes de destino."],"metadata":{"id":"owqEy_nk4kaD"}},{"cell_type":"code","source":["labels = dataset_df_train_completo[\"label\"]\n","dataset_df_train, dataset_df_val = train_test_split(dataset_df_train_completo, test_size=0.2, random_state=42, stratify=labels)"],"metadata":{"id":"-n7DNkytoc_o","executionInfo":{"status":"ok","timestamp":1686503916607,"user_tz":180,"elapsed":21,"user":{"displayName":"Renata Rabelo","userId":"10460000738836966178"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["### **Construção da arquitetura da rede neural convolucional**"],"metadata":{"id":"0fRgAAxmojea"}},{"cell_type":"code","source":["def build_cnn(input_shape=(64, 64, 3), n_classes=83):\n","    base_model = Sequential([\n","        Conv2D(filters=32, kernel_size=(4,4), activation='relu', input_shape=input_shape),\n","        MaxPool2D(pool_size=(2,2)),\n","        Conv2D(filters=32, kernel_size=(4,4), activation='relu'),\n","        MaxPool2D(pool_size=(2,2)),\n","        Flatten(),\n","        Dense(256, activation='relu'),\n","    ])\n","\n","    # Congela as camadas do modelo base\n","    for layer in base_model.layers:\n","        layer.trainable = False\n","\n","    # Cria um novo modelo, acrescentando a nova camada densa\n","    model = Sequential([\n","        base_model,\n","        Dense(n_classes, activation='softmax')\n","    ])\n","\n","    return model\n","\n","input_shape = (100, 100, 3)\n","n_classes = 83\n","\n","model = build_cnn(input_shape, n_classes)\n","opt = SGD(learning_rate=0.01)\n","model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XO5D6QXeogRi","executionInfo":{"status":"ok","timestamp":1686503916608,"user_tz":180,"elapsed":22,"user":{"displayName":"Renata Rabelo","userId":"10460000738836966178"}},"outputId":"829afa6d-2917-4a4f-b7c5-bef829e6afc5"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," sequential (Sequential)     (None, 256)               3983168   \n","                                                                 \n"," dense_1 (Dense)             (None, 83)                21331     \n","                                                                 \n","=================================================================\n","Total params: 4,004,499\n","Trainable params: 21,331\n","Non-trainable params: 3,983,168\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["### **Pré-processamento dos dados**"],"metadata":{"id":"rgbNKiMIpDBa"}},{"cell_type":"markdown","source":["A função preprocess_faces_dataset é definida para pré-processar os dados de imagem. Ela itera sobre o dataframe do dataset de treinamento ou validação, carrega cada imagem usando a função load_img do Keras, redimensiona para o tamanho desejado, converte para um array NumPy e normaliza os valores dos pixels dividindo por 255. O resultado é um array de imagens (X) e um array de rótulos (y)."],"metadata":{"id":"X8FFNzhY4t2a"}},{"cell_type":"code","source":["def preprocess_faces_dataset(dataset_df, input_shape=(64, 64), verbose=0):\n","    image_list = []\n","    label_list = []\n","\n","    for index, row in dataset_df.iterrows():\n","        img_path = os.path.join(data_dir, 'train', row['image-pathname'])\n","        img = load_img(img_path, target_size=input_shape)\n","        img = img_to_array(img) / 255.0\n","        image_list.append(img)\n","        label_list.append(row['label'])\n","\n","        if verbose and (index % verbose) == 0:\n","            print(f'{index + 1}/{len(dataset_df)} - {img_path}')\n","\n","    X = np.array(image_list)\n","    y = np.array(label_list)\n","\n","    return X, y"],"metadata":{"id":"3GLSwm9_pGSz","executionInfo":{"status":"ok","timestamp":1686503916609,"user_tz":180,"elapsed":12,"user":{"displayName":"Renata Rabelo","userId":"10460000738836966178"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["Os conjuntos de treinamento e validação são pré-processados usando a função preprocess_faces_dataset."],"metadata":{"id":"0pjVnnH-5OXS"}},{"cell_type":"code","source":["X_train, y_train = preprocess_faces_dataset(dataset_df_train, input_shape)\n","X_val, y_val = preprocess_faces_dataset(dataset_df_val, input_shape)"],"metadata":{"id":"sWPTgbdWpVE6","colab":{"base_uri":"https://localhost:8080/","height":342},"executionInfo":{"status":"error","timestamp":1686506502122,"user_tz":180,"elapsed":380501,"user":{"displayName":"Renata Rabelo","userId":"10460000738836966178"}},"outputId":"f0dde2b6-c855-4242-a735-23a08c8051e0"},"execution_count":8,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-436e00d765ce>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_faces_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_df_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_faces_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_df_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-6e45cbe88d4a>\u001b[0m in \u001b[0;36mpreprocess_faces_dataset\u001b[0;34m(dataset_df, input_shape, verbose)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image-pathname'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mimage_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/image_utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         raise TypeError(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["### **Callbacks**"],"metadata":{"id":"DhCbOkRz8-Ry"}},{"cell_type":"markdown","source":["No código abaixo é feita a definição dos callbacks early_stopping_cb e tensorboard_callback para monitorar o treinamento e evitar overfitting."],"metadata":{"id":"o5ub7gN89CvK"}},{"cell_type":"code","source":["early_stopping_cb = EarlyStopping(patience=10, restore_best_weights=True)\n","tensorboard_callback = TensorBoard(log_dir='logs/')"],"metadata":{"id":"ltKMSrRc1-nq","executionInfo":{"status":"aborted","timestamp":1686506502124,"user_tz":180,"elapsed":2,"user":{"displayName":"Renata Rabelo","userId":"10460000738836966178"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Treinamento do modelo**"],"metadata":{"id":"Dh5FKUIH9Tdt"}},{"cell_type":"markdown","source":["Treinamento do modelo usando o método fit, passando os dados de treinamento e validação, número de epochs, tamanho do lote e callbacks"],"metadata":{"id":"Z9M95UCK9WSU"}},{"cell_type":"code","source":["history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping_cb, tensorboard_callback])"],"metadata":{"id":"DGJc__SN2AcK","executionInfo":{"status":"aborted","timestamp":1686506502126,"user_tz":180,"elapsed":4,"user":{"displayName":"Renata Rabelo","userId":"10460000738836966178"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Visualizando o histórico de treinamento**"],"metadata":{"id":"yW0kpBrQ-ird"}},{"cell_type":"markdown","source":["O código abaixo cria um DataFrame do pandas chamado history_df a partir do objeto history.history, que contém as métricas de treinamento e validação ao longo das épocas durante o treinamento do modelo.\n","\n","Em seguida, são plotados dois gráficos. O primeiro gráfico mostra as curvas de perda (loss) de treinamento e validação ao longo das épocas. O eixo x representa as épocas e o eixo y representa a perda. O segundo gráfico mostra as curvas de acurácia (accuracy) de treinamento e validação ao longo das épocas. O eixo x representa as épocas e o eixo y representa a acurácia.\n","\n","Esses gráficos ajudam a visualizar o desempenho do modelo durante o treinamento e a analisar a convergência e o overfitting. A função plot do pandas é usada para traçar os gráficos e as funções grid, xlabel e ylabel do matplotlib.pyplot são usadas para adicionar a grade e rótulos aos eixos dos gráficos."],"metadata":{"id":"Q-Fj1H2N_skC"}},{"cell_type":"code","source":["history_df = pd.DataFrame(history.history)\n","\n","history_df[['loss', 'val_loss']].plot(figsize=(8, 5))\n","plt.grid(True)\n","plt.xlabel('Epochs')\n","plt.ylabel('Score')\n","\n","history_df[['accuracy', 'val_accuracy']].plot(figsize=(8, 5))\n","plt.grid(True)\n","plt.xlabel('Epochs')\n","plt.ylabel('Score')"],"metadata":{"id":"ry7Q0NZQ_K86","executionInfo":{"status":"aborted","timestamp":1686506502126,"user_tz":180,"elapsed":4,"user":{"displayName":"Renata Rabelo","userId":"10460000738836966178"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Salvando o modelo treinado**"],"metadata":{"id":"utggApwj9bAh"}},{"cell_type":"markdown","source":["O modelo treinado está sendo salvo em um arquivo HDF5"],"metadata":{"id":"J_A0kOES9eqJ"}},{"cell_type":"code","source":["model.save('model.h5')"],"metadata":{"id":"w8n8ktYU2C8x","executionInfo":{"status":"aborted","timestamp":1686506502127,"user_tz":180,"elapsed":5,"user":{"displayName":"Renata Rabelo","userId":"10460000738836966178"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Criação do diretório de saída para salvar os conjuntos de dados pré-processados**"],"metadata":{"id":"OdV6Wpl9pYQi"}},{"cell_type":"markdown","source":["O código abaixo faz a criação de um diretório de saída, e na sequencia, o salvamento dos conjuntos de dados e arquivos numpy pré-processados"],"metadata":{"id":"tVis8N-s9q5e"}},{"cell_type":"code","source":["out_dir = '/content/drive/MyDrive/Colab Notebooks/Kaggle/preprocessed_02'\n","\n","if not os.path.exists(out_dir):\n","    os.makedirs(out_dir)\n","\n","dataset_df_train_completo.to_csv(os.path.join(out_dir, 'full_train.csv'), index=False)\n","dataset_df_train.to_csv(os.path.join(out_dir, 'train.csv'), index=False)\n","dataset_df_val.to_csv(os.path.join(out_dir, 'validation.csv'), index=False)\n","\n","np.save(os.path.join(out_dir, 'X_train.npy'), X_train)\n","np.save(os.path.join(out_dir, 'y_train.npy'), y_train)\n","np.save(os.path.join(out_dir, 'X_val.npy'), X_val)\n","np.save(os.path.join(out_dir, 'y_val.npy'), y_val)"],"metadata":{"id":"AOUJGl35pa5m","executionInfo":{"status":"aborted","timestamp":1686506502127,"user_tz":180,"elapsed":5,"user":{"displayName":"Renata Rabelo","userId":"10460000738836966178"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Montando o arquivo de submissão**\n","\n"],"metadata":{"id":"K_OuWe7FDpkA"}},{"cell_type":"code","source":["# Define uma função chamada read_test para ler e pré-processar as imagens de teste\n","def read_test(dataset_df, input_shape=(64, 64), verbose=0):\n","    image_list = []\n","    label_list = []\n","\n","    for index, row in dataset_df.iterrows():\n","        img_path = os.path.join(data_dir, 'test', row['image-pathname'])\n","        img = load_img(img_path, target_size=input_shape)\n","        img = img_to_array(img) / 255.0\n","        image_list.append(img)\n","\n","        if verbose and (index % verbose) == 0:\n","            print(f'{index + 1}/{len(dataset_df)} - {img_path}')\n","\n","    X = np.array(image_list)\n","\n","    return X"],"metadata":{"id":"v-hDqeHeFzEK","executionInfo":{"status":"aborted","timestamp":1686506502127,"user_tz":180,"elapsed":5,"user":{"displayName":"Renata Rabelo","userId":"10460000738836966178"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Chama a função read_test para carregar e pré-processar as imagens de teste\n","X_test = read_test(dataset_df_test, input_shape=(100, 100), verbose=1)"],"metadata":{"id":"lhe3hArbE27g","executionInfo":{"status":"aborted","timestamp":1686506502128,"user_tz":180,"elapsed":6,"user":{"displayName":"Renata Rabelo","userId":"10460000738836966178"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Faz previsões usando o modelo treinado para as imagens de teste\n","y_test_proba = model.predict(X_test)\n","y_test_pred = np.argmax(y_test_proba, axis=1)\n","\n","# Converte as previsões em rótulos de classe usando label_encoder.inverse_transform\n","# Cria um DataFrame com as colunas \"image-id\" e \"prediction\" e o salva como arquivo CSV\n","df = pd.DataFrame({\"image-id\": dataset_df_test[\"image-id\"], \"prediction\": list(label_encoder.inverse_transform(y_test_pred))})\n","df.to_csv(\"results_cnn.csv\", index=False)"],"metadata":{"id":"cftnmePwEz8-","executionInfo":{"status":"aborted","timestamp":1686506502128,"user_tz":180,"elapsed":6,"user":{"displayName":"Renata Rabelo","userId":"10460000738836966178"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Repete o processo anterior, salvando o DataFrame em um arquivo chamado \"results.csv\"\n","df = pd.DataFrame({\"image-id\": dataset_df_test[\"image-id\"], \"prediction\": list(label_encoder.inverse_transform(y_test_pred))})\n","df.to_csv('/content/drive/MyDrive/Colab Notebooks/Kaggle/results_comTL.csv', index=False)"],"metadata":{"id":"Hxlq2HlVDxbc","executionInfo":{"status":"aborted","timestamp":1686506502128,"user_tz":180,"elapsed":6,"user":{"displayName":"Renata Rabelo","userId":"10460000738836966178"}}},"execution_count":null,"outputs":[]}]}