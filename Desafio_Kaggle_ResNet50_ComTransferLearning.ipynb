{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1LazbQiwfaiX7YOgX4OO4cgpB392kZFJb","timestamp":1686505498639},{"file_id":"1DLer2HUyaSpJxcAwr6YdmpDtFoSkX2Wv","timestamp":1686503632954}],"authorship_tag":"ABX9TyOpytAn58ADdzsthCwm8kws"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**D3APL: Aplicações em Ciência de Dados** <br/>\n","IFSP Campinas\n","\n","Renata Rabelo e Mariana Cabride\n","\n","Prof. Dr. Samuel Martins (Samuka) <br/><br/>"],"metadata":{"id":"dF4ixE_CnLqa"}},{"cell_type":"markdown","source":["**Descrição:** Este código utiliza a arquitetura ResNet50 com pesos pré-treinados para treinar um novo modelo. As camadas de convolução da ResNet50 são congeladas, e novas camadas densas são adicionadas no final para classificação. O otimizador Adam é usado para treinamento, e os callbacks EarlyStopping e TensorBoard são usados para parar o treinamento se o desempenho não melhorar após 10 épocas e para registrar os logs de treinamento, respectivamente.\n"],"metadata":{"id":"_cfKP5GwPuH8"}},{"cell_type":"markdown","source":["### **Carregando as bibliotecas**"],"metadata":{"id":"HYQt4-8mnOBH"}},{"cell_type":"markdown","source":[" TensorFlow, os, pandas, numpy e random são importados. Essas bibliotecas são usadas para manipulação de dados, treinamento de redes neurais e outras operações relacionadas."],"metadata":{"id":"wQcd0Hac4N_f"}},{"cell_type":"code","source":["!pip install Pillow"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-d0ZYRqX1N9g","executionInfo":{"status":"ok","timestamp":1686510047393,"user_tz":180,"elapsed":4477,"user":{"displayName":"Renata Rabelo","userId":"10460000738836966178"}},"outputId":"dd334a52-1614-4dda-e7b7-c009049e4028"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (8.4.0)\n"]}]},{"cell_type":"code","source":["import os\n","import random\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.applications.resnet50 import ResNet50\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","from tensorflow.keras.callbacks import EarlyStopping, TensorBoard"],"metadata":{"id":"-wEmMTMmnT8V","executionInfo":{"status":"ok","timestamp":1686510052573,"user_tz":180,"elapsed":1365,"user":{"displayName":"Renata Rabelo","userId":"10460000738836966178"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["### **Configuração dos seeds aleatórios**"],"metadata":{"id":"6kd-S4X3ndca"}},{"cell_type":"markdown","source":["Função reset_random_seeds(): Essa função configura as sementes aleatórias para garantir a reprodutibilidade dos resultados. Ela define as sementes para TensorFlow, NumPy e Python's Random."],"metadata":{"id":"eIPTVhs04XG9"}},{"cell_type":"code","source":["def reset_random_seeds(seed=42):\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    tf.random.set_seed(seed)\n","    np.random.seed(seed)\n","    random.seed(seed)\n","\n","reset_random_seeds()"],"metadata":{"id":"8TixJt_6ngxC","executionInfo":{"status":"ok","timestamp":1686510055865,"user_tz":180,"elapsed":580,"user":{"displayName":"Renata Rabelo","userId":"10460000738836966178"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["### **Montagem do Google Drive**"],"metadata":{"id":"73Fl0tbynqk6"}},{"cell_type":"markdown","source":["O código monta o Google Drive para acessar os arquivos de dados. Ele usa a biblioteca do Google Colab para essa finalidade."],"metadata":{"id":"QcPB8vqO4azz"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yj9WMKL8nsJ2","executionInfo":{"status":"ok","timestamp":1686510066109,"user_tz":180,"elapsed":6515,"user":{"displayName":"Renata Rabelo","userId":"10460000738836966178"}},"outputId":"bb50fc3c-90dc-4be4-c392-d28d68396aed"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["### **Carregamento dos dados**"],"metadata":{"id":"nsxC-3GooQiM"}},{"cell_type":"markdown","source":["Os arquivos de treinamento e teste são carregados usando o pandas. Eles são armazenados em dataframes (dataset_df_train_completo e dataset_df_test, respectivamente). Após essa etapa, é feita a conversão dos rótulos das classes de formato de texto para números inteiros usando o LabelEncoder."],"metadata":{"id":"7cRXhUII4f3N"}},{"cell_type":"code","source":["data_dir = '/content/drive/MyDrive/Colab Notebooks/Kaggle/ifsp-d3apl-2023-face-recognition'\n","train_file = os.path.join(data_dir, 'train.csv')\n","test_file = os.path.join(data_dir, 'test.csv')\n","\n","dataset_df_train_completo = pd.read_csv(train_file)\n","dataset_df_test = pd.read_csv(test_file)\n","\n","# Conversão dos rótulos em formato de texto para números inteiros\n","label_encoder = LabelEncoder()\n","dataset_df_train_completo[\"label\"] = label_encoder.fit_transform(dataset_df_train_completo[\"label\"])"],"metadata":{"id":"KYjkzrtMnvN-","executionInfo":{"status":"ok","timestamp":1686510068509,"user_tz":180,"elapsed":2,"user":{"displayName":"Renata Rabelo","userId":"10460000738836966178"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["### **Divisão do conjunto de treinamento completo em treinamento e validação**"],"metadata":{"id":"twjjtztWoadK"}},{"cell_type":"markdown","source":["O conjunto de treinamento completo (dataset_df_train_completo) é dividido em conjuntos de treinamento e validação usando a função train_test_split do scikit-learn. Os dados são divididos em uma proporção de 80% para treinamento e 20% para validação. A variável labels contém as classes de destino."],"metadata":{"id":"owqEy_nk4kaD"}},{"cell_type":"code","source":["labels = dataset_df_train_completo[\"label\"]\n","dataset_df_train, dataset_df_val = train_test_split(dataset_df_train_completo, test_size=0.2, random_state=42, stratify=labels)"],"metadata":{"id":"-n7DNkytoc_o","executionInfo":{"status":"ok","timestamp":1686510074707,"user_tz":180,"elapsed":11,"user":{"displayName":"Renata Rabelo","userId":"10460000738836966178"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["### **Construção da arquitetura da rede neural convolucional**"],"metadata":{"id":"0fRgAAxmojea"}},{"cell_type":"code","source":["def build_model(input_shape=(100, 100, 3), n_classes=83):\n","    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n","    \n","    for layer in base_model.layers:\n","        layer.trainable = False\n","\n","    model = Sequential([\n","        base_model,\n","        GlobalAveragePooling2D(),\n","        Dense(256, activation='relu'),\n","        Dense(n_classes, activation='softmax')\n","    ])\n","\n","    return model\n","\n","input_shape = (100, 100, 3)\n","n_classes = 83\n","\n","model = build_model(input_shape, n_classes)\n","opt = Adam()\n","model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XO5D6QXeogRi","executionInfo":{"status":"ok","timestamp":1686510084064,"user_tz":180,"elapsed":6824,"user":{"displayName":"Renata Rabelo","userId":"10460000738836966178"}},"outputId":"0ee8e62f-0330-4dd8-c2ac-a0319522e0d7"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," resnet50 (Functional)       (None, 4, 4, 2048)        23587712  \n","                                                                 \n"," global_average_pooling2d_1   (None, 2048)             0         \n"," (GlobalAveragePooling2D)                                        \n","                                                                 \n"," dense_2 (Dense)             (None, 256)               524544    \n","                                                                 \n"," dense_3 (Dense)             (None, 83)                21331     \n","                                                                 \n","=================================================================\n","Total params: 24,133,587\n","Trainable params: 545,875\n","Non-trainable params: 23,587,712\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["### **Pré-processamento dos dados**"],"metadata":{"id":"rgbNKiMIpDBa"}},{"cell_type":"markdown","source":["A função preprocess_faces_dataset é definida para pré-processar os dados de imagem. Ela itera sobre o dataframe do dataset de treinamento ou validação, carrega cada imagem usando a função load_img do Keras, redimensiona para o tamanho desejado, converte para um array NumPy e normaliza os valores dos pixels dividindo por 255. O resultado é um array de imagens (X) e um array de rótulos (y)."],"metadata":{"id":"X8FFNzhY4t2a"}},{"cell_type":"code","source":["def preprocess_faces_dataset(dataset_df, input_shape=(100, 100), verbose=0):\n","    image_list = []\n","    label_list = []\n","\n","    for index, row in dataset_df.iterrows():\n","        img_path = os.path.join(data_dir, 'train', row['image-pathname'])\n","        img = load_img(img_path, target_size=input_shape)\n","        img = img_to_array(img) / 255.0\n","        image_list.append(img)\n","        label_list.append(row['label'])\n","\n","        if verbose and (index % verbose) == 0:\n","            print(f'{index + 1}/{len(dataset_df)} - {img_path}')\n","\n","    X = np.array(image_list)\n","    y = np.array(label_list)\n","\n","    return X, y"],"metadata":{"id":"3GLSwm9_pGSz","executionInfo":{"status":"ok","timestamp":1686510090421,"user_tz":180,"elapsed":594,"user":{"displayName":"Renata Rabelo","userId":"10460000738836966178"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["Os conjuntos de treinamento e validação são pré-processados usando a função preprocess_faces_dataset."],"metadata":{"id":"0pjVnnH-5OXS"}},{"cell_type":"code","source":["X_train, y_train = preprocess_faces_dataset(dataset_df_train, input_shape)\n","X_val, y_val = preprocess_faces_dataset(dataset_df_val, input_shape)"],"metadata":{"id":"sWPTgbdWpVE6","executionInfo":{"status":"ok","timestamp":1686513096541,"user_tz":180,"elapsed":3003153,"user":{"displayName":"Renata Rabelo","userId":"10460000738836966178"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["### **Callbacks**"],"metadata":{"id":"DhCbOkRz8-Ry"}},{"cell_type":"markdown","source":["No código abaixo é feita a definição dos callbacks early_stopping_cb e tensorboard_callback para monitorar o treinamento e evitar overfitting."],"metadata":{"id":"o5ub7gN89CvK"}},{"cell_type":"code","source":["early_stopping_cb = EarlyStopping(patience=10, restore_best_weights=True)\n","tensorboard_callback = TensorBoard(log_dir='logs/')"],"metadata":{"id":"ltKMSrRc1-nq","executionInfo":{"status":"ok","timestamp":1686513096543,"user_tz":180,"elapsed":57,"user":{"displayName":"Renata Rabelo","userId":"10460000738836966178"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["## **Treinamento do modelo**"],"metadata":{"id":"Dh5FKUIH9Tdt"}},{"cell_type":"markdown","source":["Treinamento do modelo usando o método fit, passando os dados de treinamento e validação, número de epochs, tamanho do lote e callbacks"],"metadata":{"id":"Z9M95UCK9WSU"}},{"cell_type":"code","source":["history = model.fit(X_train, y_train, epochs=100, batch_size=50, validation_data=(X_val, y_val), callbacks=[early_stopping_cb, tensorboard_callback])"],"metadata":{"id":"DGJc__SN2AcK","colab":{"base_uri":"https://localhost:8080/"},"outputId":"95212bd0-a3df-478e-b8b3-f72919efa26c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","156/156 [==============================] - 505s 3s/step - loss: 4.3490 - accuracy: 0.0267 - val_loss: 4.3394 - val_accuracy: 0.0277\n","Epoch 2/100\n","156/156 [==============================] - 506s 3s/step - loss: 4.3435 - accuracy: 0.0290 - val_loss: 4.3407 - val_accuracy: 0.0323\n","Epoch 3/100\n","156/156 [==============================] - 507s 3s/step - loss: 4.3397 - accuracy: 0.0280 - val_loss: 4.3316 - val_accuracy: 0.0277\n","Epoch 4/100\n","156/156 [==============================] - 507s 3s/step - loss: 4.3339 - accuracy: 0.0290 - val_loss: 4.3300 - val_accuracy: 0.0318\n","Epoch 5/100\n","156/156 [==============================] - ETA: 0s - loss: 4.3290 - accuracy: 0.0304"]}]},{"cell_type":"markdown","source":["#### **Visualizando o histórico de treinamento**"],"metadata":{"id":"yW0kpBrQ-ird"}},{"cell_type":"markdown","source":["O código abaixo cria um DataFrame do pandas chamado history_df a partir do objeto history.history, que contém as métricas de treinamento e validação ao longo das épocas durante o treinamento do modelo.\n","\n","Em seguida, são plotados dois gráficos. O primeiro gráfico mostra as curvas de perda (loss) de treinamento e validação ao longo das épocas. O eixo x representa as épocas e o eixo y representa a perda. O segundo gráfico mostra as curvas de acurácia (accuracy) de treinamento e validação ao longo das épocas. O eixo x representa as épocas e o eixo y representa a acurácia.\n","\n","Esses gráficos ajudam a visualizar o desempenho do modelo durante o treinamento e a analisar a convergência e o overfitting. A função plot do pandas é usada para traçar os gráficos e as funções grid, xlabel e ylabel do matplotlib.pyplot são usadas para adicionar a grade e rótulos aos eixos dos gráficos."],"metadata":{"id":"Q-Fj1H2N_skC"}},{"cell_type":"code","source":["history_df = pd.DataFrame(history.history)\n","\n","history_df[['loss', 'val_loss']].plot(figsize=(8, 5))\n","plt.grid(True)\n","plt.xlabel('Epochs')\n","plt.ylabel('Score')\n","\n","history_df[['accuracy', 'val_accuracy']].plot(figsize=(8, 5))\n","plt.grid(True)\n","plt.xlabel('Epochs')\n","plt.ylabel('Score')"],"metadata":{"id":"ry7Q0NZQ_K86","executionInfo":{"status":"aborted","timestamp":1686513664614,"user_tz":180,"elapsed":7,"user":{"displayName":"Renata Rabelo","userId":"10460000738836966178"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Salvando o modelo treinado**"],"metadata":{"id":"utggApwj9bAh"}},{"cell_type":"markdown","source":["O modelo treinado está sendo salvo em um arquivo HDF5"],"metadata":{"id":"J_A0kOES9eqJ"}},{"cell_type":"code","source":["model.save('modelResNet.h5')"],"metadata":{"id":"w8n8ktYU2C8x","executionInfo":{"status":"aborted","timestamp":1686513664615,"user_tz":180,"elapsed":7,"user":{"displayName":"Renata Rabelo","userId":"10460000738836966178"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Criação do diretório de saída para salvar os conjuntos de dados pré-processados**"],"metadata":{"id":"OdV6Wpl9pYQi"}},{"cell_type":"markdown","source":["O código abaixo faz a criação de um diretório de saída, e na sequencia, o salvamento dos conjuntos de dados e arquivos numpy pré-processados"],"metadata":{"id":"tVis8N-s9q5e"}},{"cell_type":"code","source":["out_dir = '/content/drive/MyDrive/Colab Notebooks/Kaggle/preprocessed_03'\n","\n","if not os.path.exists(out_dir):\n","    os.makedirs(out_dir)\n","\n","dataset_df_train_completo.to_csv(os.path.join(out_dir, 'full_train.csv'), index=False)\n","dataset_df_train.to_csv(os.path.join(out_dir, 'train.csv'), index=False)\n","dataset_df_val.to_csv(os.path.join(out_dir, 'validation.csv'), index=False)\n","\n","np.save(os.path.join(out_dir, 'X_train.npy'), X_train)\n","np.save(os.path.join(out_dir, 'y_train.npy'), y_train)\n","np.save(os.path.join(out_dir, 'X_val.npy'), X_val)\n","np.save(os.path.join(out_dir, 'y_val.npy'), y_val)"],"metadata":{"id":"AOUJGl35pa5m","executionInfo":{"status":"aborted","timestamp":1686513664615,"user_tz":180,"elapsed":7,"user":{"displayName":"Renata Rabelo","userId":"10460000738836966178"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Montando o arquivo de submissão**\n","\n"],"metadata":{"id":"K_OuWe7FDpkA"}},{"cell_type":"code","source":["# Define uma função chamada read_test para ler e pré-processar as imagens de teste\n","def read_test(dataset_df, input_shape=(100, 100), verbose=0):\n","    image_list = []\n","\n","    for index, row in dataset_df.iterrows():\n","        img_path = os.path.join(data_dir, 'test', row['image-pathname'])\n","        img = load_img(img_path, target_size=input_shape)\n","        img = img_to_array(img) / 255.0\n","        image_list.append(img)\n","\n","        if verbose and (index % verbose) == 0:\n","            print(f'{index + 1}/{len(dataset_df)} - {img_path}')\n","\n","    X = np.array(image_list)\n","\n","    return X"],"metadata":{"id":"v-hDqeHeFzEK","executionInfo":{"status":"aborted","timestamp":1686513664615,"user_tz":180,"elapsed":7,"user":{"displayName":"Renata Rabelo","userId":"10460000738836966178"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Chama a função read_test para carregar e pré-processar as imagens de teste\n","X_test = read_test(dataset_df_test, input_shape=(100, 100), verbose=1)"],"metadata":{"id":"lhe3hArbE27g","executionInfo":{"status":"aborted","timestamp":1686513664615,"user_tz":180,"elapsed":7,"user":{"displayName":"Renata Rabelo","userId":"10460000738836966178"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Faz previsões usando o modelo treinado para as imagens de teste\n","y_test_proba = model.predict(X_test)\n","y_test_pred = np.argmax(y_test_proba, axis=1)\n","\n","# Converte as previsões em rótulos de classe usando label_encoder.inverse_transform\n","# Cria um DataFrame com as colunas \"image-id\" e \"prediction\" e o salva como arquivo CSV\n","df = pd.DataFrame({\"image-id\": dataset_df_test[\"image-id\"], \"prediction\": list(label_encoder.inverse_transform(y_test_pred))})\n","df.to_csv(\"results_cnn.csv\", index=False)"],"metadata":{"id":"cftnmePwEz8-","executionInfo":{"status":"aborted","timestamp":1686513664616,"user_tz":180,"elapsed":8,"user":{"displayName":"Renata Rabelo","userId":"10460000738836966178"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Repete o processo anterior, salvando o DataFrame em um arquivo chamado \"results.csv\"\n","df = pd.DataFrame({\"image-id\": dataset_df_test[\"image-id\"], \"prediction\": list(label_encoder.inverse_transform(y_test_pred))})\n","df.to_csv('/content/drive/MyDrive/Colab Notebooks/Kaggle/results_ResNet.csv', index=False)"],"metadata":{"id":"Hxlq2HlVDxbc","executionInfo":{"status":"aborted","timestamp":1686513664616,"user_tz":180,"elapsed":8,"user":{"displayName":"Renata Rabelo","userId":"10460000738836966178"}}},"execution_count":null,"outputs":[]}]}